{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spartan.utils.sklearn import model_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import sklearn.preprocessing as ppro\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA, RandomizedPCA, KernelPCA, FactorAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tax_path = \"/home/gus/MEGAsync/zim/main/BCH/Projects/Amy/2016-01-07_~_16s_data/otu_table_mc2_w_tax_no_pynast_failures.biom.TAXON.tsv\"\n",
    "map_path = \"/home/gus/MEGAsync/zim/main/BCH/Projects/Amy/2016-01-07_~_16s_data/BL6SPFDec16map.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tax = pd.read_csv(filepath_or_buffer=tax_path, sep='\\t', \n",
    "                  quoting=0, skipinitialspace=False, lineterminator=None, header='infer', index_col=None, names=None)\n",
    "\n",
    "meta = pd.read_csv(filepath_or_buffer=map_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tax.index = tax['OTU ID'].values\n",
    "tax = tax.drop(['OTU ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tax_scaled = tax.T.apply(lambda m: (m - m.mean())/m.std()).T\n",
    "# tax_scaled = tax.T.apply(lambda m: (m / m.sum())).T\n",
    "# tax_scaled = tax\n",
    "\n",
    "tax_shrunk = tax.sum().min() / tax.sum() * tax\n",
    "\n",
    "tax_scaled = tax_shrunk.T.apply(lambda m: (m - m.mean())/m.std()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tax_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta.SampleID = meta.SampleID.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# meta.set_index('SampleID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta['WT or not'] = meta.Genotype1.apply(lambda i: i if i == 'WT' else 'mutant')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_table = meta.set_index('SampleID').join(tax_scaled.T).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode 'y' (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_geno_any_mut = full_table['WT or not']\n",
    "y_geno_spc_mut = full_table['Genotype1']\n",
    "geno_encoder = ppro.LabelEncoder()\n",
    "y_geno_encoded_any = geno_encoder.fit_transform(y_geno_any_mut)\n",
    "y_geno_encoded_spc = geno_encoder.fit_transform(y_geno_spc_mut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode 'X' (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine (or not) the categorical and numerical data types for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_cols_cat = list(full_table.columns[[2,7]].values)\n",
    "X_cols_num = list(full_table.columns[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_cols_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the dummy variable columns for the original categorical data columns\n",
    "# HOPEFULLY we dont run into colinearity issues\n",
    "X_data_cat = pd.get_dummies(full_table[X_cols_cat].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To avoid colinearity we remove one column from each class of categorical \n",
    "X_data_cat = X_data_cat[['Gender_F', 'Cage_943947', 'Cage_943948']]\n",
    "X_data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put all data columns together\n",
    "X = pd.concat([X_data_cat,full_table[X_cols_num]],axis=1) # Accounting for Cages and Sex\n",
    "# X = full_table[X_cols_num] # IGNORING Cages and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repandasify(array, y_names, X_names=None):\n",
    "    df = pd.DataFrame(data=array, index=y_names,columns=X_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pca = PCA(n_components=2, whiten=False)\n",
    "pca = RandomizedPCA(n_components=2, whiten=False)\n",
    "# pca = KernelPCA(n_components=2,)\n",
    "# pca = FactorAnalysis(n_components=2, iterated_power=5)\n",
    "pca_t = pca.fit_transform(X,y_geno_encoded_spc)\n",
    "# top_n_comp = 2\n",
    "# print('explained_variance_ratio_ of top {num}: {val}'.format(num=top_n_comp,val=pca.explained_variance_ratio_[:top_n_comp].sum()))\n",
    "\n",
    "pca_t_l = repandasify(array=pca_t, y_names=geno_encoder.inverse_transform(y_geno_encoded_spc), X_names=['PC {v_}'.format(v_=v+1) for v in range(len(pca_t[0]))])\n",
    "print(pca_t_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_t_l = repandasify(array=pca_t, y_names=geno_encoder.inverse_transform(y_geno_encoded_spc), X_names=['PC {v_}'.format(v_=v+1) for v in range(len(pca_t[0]))])\n",
    "\n",
    "pca_t_l['geno'] = pca_t_l.index.values\n",
    "pca_t_l = pca_t_l.reset_index(drop=True)\n",
    "pca_t_l['Cage'] = full_table.Cage.astype(str)\n",
    "pca_t_l['Sex'] = full_table.Gender\n",
    "pca_t_l['Specific Genotype'] = full_table.Genotype1\n",
    "# pca_t_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.color_palette(sns.color_palette(\"hls\", 2)):\n",
    "    with sns.axes_style(\"white\"):\n",
    "        sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l.append(pca_t_l.iloc[9,:]), #sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l,\n",
    "                   hue='Specific Genotype', palette=None,\n",
    "                   fit_reg=False,\n",
    "                   scatter_kws={'alpha':0.7}\n",
    "                  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Build a forest and compute the feature importances\n",
    "# forest = ExtraTreesClassifier(n_estimators=10000,\n",
    "#                               random_state=0,\n",
    "#                               n_jobs=8\n",
    "#                              )\n",
    "\n",
    "# forest.fit(X, y_geno_encoded)\n",
    "# importances = forest.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "#              axis=0)\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "# n_features = 7\n",
    "\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(n_features):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(n_features), importances[indices][:n_features],\n",
    "#        color=\"r\", yerr=std[indices][:n_features], align=\"center\")\n",
    "# plt.xticks(range(n_features), indices[:n_features])\n",
    "# # plt.xlim([-1, n_features])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees Decompositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# top_n_sorted_features = 7\n",
    "\n",
    "# # pca = PCA(n_components=2, whiten=False)\n",
    "# pca = RandomizedPCA(n_components=2, whiten=False)\n",
    "# # pca = KernelPCA(n_components=2,)\n",
    "# # pca = FactorAnalysis(n_components=2, iterated_power=5)\n",
    "# pca_t = pca.fit_transform(X_tree_sorted.iloc[:,:top_n_sorted_features],y_geno_encoded)\n",
    "# # top_n_comp = 2\n",
    "# # print('explained_variance_ratio_ of top {num}: {val}'.format(num=top_n_comp,val=pca.explained_variance_ratio_[:top_n_comp].sum()))\n",
    "\n",
    "# pca_t_l = repandasify(array=pca_t, y_names=geno_encoder.inverse_transform(y_geno_encoded), X_names=['PC {v_}'.format(v_=v+1) for v in range(len(pca_t[0]))])\n",
    "# print(pca_t_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pca_t_l = repandasify(array=pca_t, y_names=geno_encoder.inverse_transform(y_geno_encoded), X_names=['PC {v_}'.format(v_=v+1) for v in range(len(pca_t[0]))])\n",
    "\n",
    "# pca_t_l['geno'] = pca_t_l.index.values\n",
    "# pca_t_l = pca_t_l.reset_index(drop=True)\n",
    "# pca_t_l['Cage'] = full_table.Cage.astype(str)\n",
    "# pca_t_l['Sex'] = full_table.Gender\n",
    "# pca_t_l['Specific Genotype'] = full_table.Genotype1\n",
    "# # pca_t_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_alpha = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with sns.color_palette(sns.color_palette(\"hls\", 2)):\n",
    "#     with sns.axes_style(\"white\"):\n",
    "#         sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l.append(pca_t_l.iloc[9,:]), #sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l,\n",
    "#                    hue='geno', palette=None,\n",
    "#                    fit_reg=False,\n",
    "#                    scatter_kws={'alpha':plot_alpha}\n",
    "#                   );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with sns.color_palette(sns.color_palette(\"Set2\", 3)):\n",
    "#     with sns.axes_style(\"white\"):\n",
    "#         sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l.append(pca_t_l.iloc[9,:]), #sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l,\n",
    "#                    hue='Specific Genotype', palette=None,\n",
    "#                    fit_reg=False,\n",
    "#                    scatter_kws={'alpha':plot_alpha}\n",
    "#                   );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with sns.color_palette(sns.color_palette(\"hls\", 5)):\n",
    "#     with sns.axes_style(\"white\"):\n",
    "#         sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l.append(pca_t_l.iloc[9,:]), #sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l,\n",
    "#                    hue='Cage', palette=None,\n",
    "#                    fit_reg=False,\n",
    "#                    scatter_kws={'alpha':plot_alpha}\n",
    "#                   );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with sns.color_palette(sns.color_palette(\"hls\", 2)):\n",
    "#     with sns.axes_style(\"white\"):\n",
    "#         sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l.append(pca_t_l.iloc[9,:]), #sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l,\n",
    "#                    hue='Sex', palette=None,\n",
    "#                    fit_reg=False,\n",
    "#                    scatter_kws={'alpha':plot_alpha}\n",
    "#                   );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression method\n",
    "\n",
    "- ran this a couple times manually and got varying numbers of features retained\n",
    "- I decided to \n",
    "    - run it 100 times\n",
    "    - count how frequently each feature is retained\n",
    "    - keep the top X number of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log_reg = LogisticRegression(C=1, penalty=\"l1\", multi_class='ovr', max_iter=10000, n_jobs=7).fit(X, y_geno_encoded_any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = SelectFromModel(log_reg, prefit=True)\n",
    "# X_new = model.transform(X)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.arange(X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consensus_stability_selection_rand_log_reg(X, y, clf, names=None, iters=100):\n",
    "    \"\"\"Runs classifier iters times and keeps track of which features\n",
    "    (and their mean scores)end up in the top 10%.\n",
    "    \n",
    "    Returns (Counter, mean_retained_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validations\n",
    "    if names is None:\n",
    "        try:\n",
    "            names = X.columns.values\n",
    "        except AttributeError:\n",
    "            raise Exception('If X is not a Dataframe, you must supply a value for \"names\".')\n",
    "    \n",
    "    # Biznes starts\n",
    "    feat_score_db = defaultdict(list)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while 1:\n",
    "        if i > iters:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            clf.fit(X, y)\n",
    "\n",
    "            # get first 10% of features\n",
    "            named_scores = sorted(zip(map(lambda x: round(x, 4), clf.scores_), names), reverse=True)\n",
    "\n",
    "            first_10pct = named_scores[:int(math.ceil(len(named_scores)/100*10))]\n",
    "\n",
    "            for f_score,f_name in first_10pct:\n",
    "                feat_score_db[f_name].append(f_score)\n",
    "                \n",
    "            i += 1\n",
    "            \n",
    "        except ValueError as exc:\n",
    "            msg = 'This solver needs samples of at least 2 classes'\n",
    "            if msg in exc[0]:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "            \n",
    "            \n",
    "    return feat_score_db\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rlgrg = RandomizedLogisticRegression(C=1, scaling=0.5, \n",
    "                                      sample_fraction=0.70, n_resampling=200, \n",
    "                                      verbose=False, normalize=False, \n",
    "                                      random_state=None, n_jobs=1, )\n",
    "# rlgrg.fit(X_, y_)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itr = 50\n",
    "f_sel_db = consensus_stability_selection_rand_log_reg(X=X, y=y_geno_encoded_spc,\n",
    "                                                      clf=rlgrg, names=None, iters=itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(f_sel_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot([len(l) for l in f_sel_db.values()], kde=False)\n",
    "plt.xlabel('number of times an OTU was retained');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the OTUs that were retained at least X times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_retained_otus(retained, thresh=1, iters=10):\n",
    "    \n",
    "    stable_otus = {}\n",
    "    stable_otus[\"OTU\"] = []\n",
    "    stable_otus[\"avgscr\"] = []\n",
    "    stable_otus[\"retention_rate\"] = []\n",
    "\n",
    "    for otu, scores in retained.items():\n",
    "        \n",
    "        if len(scores) >= thresh:\n",
    "            stable_otus[\"OTU\"].append(otu)\n",
    "            stable_otus[\"avgscr\"].append(np.mean(scores))\n",
    "            stable_otus[\"retention_rate\"].append(len(scores)/iters)\n",
    "            \n",
    "    return pd.DataFrame(stable_otus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_otus = process_retained_otus(retained=f_sel_db, iters=itr)\n",
    "my_otus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_otus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_otus_0_001 = my_otus.sort_values(by='avgscr', axis=0, ascending=False).query(\"\"\"avgscr > 0\"\"\")\n",
    "my_otus_0_001.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_otus_0_001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_best = X[my_otus_0_001.OTU.values]\n",
    "X_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n_sorted_features = 10\n",
    "\n",
    "# pca = PCA(n_components=2, whiten=False)\n",
    "pca = RandomizedPCA(n_components=2, whiten=False)\n",
    "# pca = KernelPCA(n_components=2,)\n",
    "# pca = FactorAnalysis(n_components=2, iterated_power=5)\n",
    "pca_t = pca.fit_transform(X_best.iloc[:,:top_n_sorted_features],y_geno_encoded_spc)\n",
    "top_n_comp = 2\n",
    "print('explained_variance_ratio_ of top {num}: {val}'.format(num=top_n_comp,val=pca.explained_variance_ratio_[:top_n_comp].sum()))\n",
    "\n",
    "pca_t_l = repandasify(array=pca_t, y_names=geno_encoder.inverse_transform(y_geno_encoded_spc), X_names=['PC {v_}'.format(v_=v+1) for v in range(len(pca_t[0]))])\n",
    "print(pca_t_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_t_l = repandasify(array=pca_t, y_names=geno_encoder.inverse_transform(y_geno_encoded_spc), X_names=['PC {v_}'.format(v_=v+1) for v in range(len(pca_t[0]))])\n",
    "\n",
    "pca_t_l['geno'] = pca_t_l.index.values\n",
    "pca_t_l = pca_t_l.reset_index(drop=True)\n",
    "pca_t_l['Cage'] = full_table.Cage.astype(str)\n",
    "pca_t_l['Sex'] = full_table.Gender\n",
    "pca_t_l['Specific Genotype'] = full_table.Genotype1\n",
    "# pca_t_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_alpha = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.color_palette(sns.color_palette(\"hls\", 3)):\n",
    "    with sns.axes_style(\"white\"):\n",
    "        sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l.append(pca_t_l.iloc[9,:]), #sns.lmplot(x='PC 1', y='PC 2', data=pca_t_l,\n",
    "                   hue='Specific Genotype', palette=None,\n",
    "                   fit_reg=False,\n",
    "                   scatter_kws={'alpha':plot_alpha}\n",
    "                  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write top 10 OTUs to file for Amy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = \"/home/gus/MEGAsync/zim/main/BCH/Projects/Amy/2016-01-07_~_16s_data/top_10_OTUs_3_genotypes.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_10 = my_otus_0_001.iloc[:10,:]\n",
    "# top_10.to_excel(out_path,index=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test crossvalidation results and preditions on reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_reduced = X[top_10.OTU.values.astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_geno_encoded_spc,\n",
    "                                                    test_size=0.33, random_state=42,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_geno_encoded_spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_param_grid = {'svc__C': 10. ** np.arange(-3, 3),\n",
    "                  'svc__gamma': 10. ** np.arange(-3, 3)\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "svc_pipe = make_pipeline(SVC(kernel='linear', random_state=42))\n",
    "\n",
    "# run the gridsearch to tune the hyper-parameters\n",
    "svc_grid = GridSearchCV(svc_pipe, param_grid=svc_param_grid, cv=3)\n",
    "\n",
    "svc_grid.fit(X_train, y_train)\n",
    "print(svc_grid.best_params_)\n",
    "\n",
    "\n",
    "# generate and plot confusion matrices\n",
    "svc_cm = confusion_matrix(y_test,svc_grid.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Non-normalized\n",
    "model_assessment.model.plot_confusion_matrix(cm=svc_cm, labels=geno_encoder.classes_, cmap='Blues', title=None,\n",
    "                 norm=False, context=None, annot=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalized\n",
    "model_assessment.plot_confusion_matrix(cm=svc_cm, labels=geno_encoder.classes_, cmap='Blues', title=None,\n",
    "                 norm=True, context=None, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfst_param_grid = {'randomforestclassifier__n_estimators': np.arange(1,15,),\n",
    "                   'randomforestclassifier__min_samples_leaf': np.arange(1,10,2)\n",
    "                  }\n",
    "\n",
    "\n",
    "\n",
    "rfst_pipe = make_pipeline(RandomForestClassifier(random_state=42,n_jobs=8))\n",
    "\n",
    "# run the gridsearch to tune the hyper-parameters\n",
    "rfst_grid = GridSearchCV(rfst_pipe, param_grid=rfst_param_grid, cv=3)\n",
    "\n",
    "\n",
    "rfst_grid.fit(X_train, y_train)\n",
    "print(rfst_grid.best_params_)\n",
    "\n",
    "\n",
    "# generate and plot confusion matrices\n",
    "rfst_cm = confusion_matrix(y_test,rfst_grid.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Non-normalized\n",
    "model_assessment.plot_confusion_matrix(cm=svc_cm, labels=geno_encoder.classes_, cmap='Blues', title=None,\n",
    "                 norm=False, context=None, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalized\n",
    "model_assessment.plot_confusion_matrix(cm=svc_cm, labels=geno_encoder.classes_, cmap='Blues', title=None,\n",
    "                 norm=Truee, context=None, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
